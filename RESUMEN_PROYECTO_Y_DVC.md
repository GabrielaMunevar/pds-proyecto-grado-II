# ğŸ“Š Resumen del Proyecto: PLS BiomÃ©dico con DVC y S3

## ğŸ¯ Â¿QuÃ© es este Proyecto?

Un sistema de **Machine Learning** que genera **Plain Language Summaries (PLS)** de textos biomÃ©dicos complejos, usando:
- **Aprendizaje semi-supervisado** para aprovechar datos no etiquetados
- **DVC** para versionado de datos y experimentos
- **AWS S3** como almacenamiento remoto escalable

---

## ğŸ“ Planteamiento del Proyecto

### Problema a Resolver

Los textos biomÃ©dicos (ensayos clÃ­nicos, estudios) son muy tÃ©cnicos y difÃ­ciles de entender para el pÃºblico general. Necesitamos un sistema que los traduzca a **lenguaje sencillo** (PLS).

### DesafÃ­o Principal

- **Datos disponibles**: ~182,700 documentos
- **Con PLS (etiquetados)**: Solo ~27% (~49k)
- **Sin PLS (no etiquetados)**: ~73% (~133k)

**SoluciÃ³n**: Usar **semi-supervisiÃ³n** para aprovechar los datos no etiquetados.

---

## ğŸ—ï¸ Arquitectura del Sistema

```
                          DATOS CRUDOS (S3)
                                 â”‚
                                 â”‚ dvc pull
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    data/raw/ (Local)                       â”‚
â”‚  â€¢ ClinicalTrials.gov (train/test)                         â”‚
â”‚  â€¢ Cochrane (pls/non_pls)                                  â”‚
â”‚  â€¢ Pfizer (incluye PDFs)                                   â”‚
â”‚  â€¢ Trial Summaries                                         â”‚
â”‚                                                            â”‚
â”‚  Total: 65,941 archivos versionados con DVC               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ dvc repro preprocess
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              1. PREPROCESAMIENTO                           â”‚
â”‚  â€¢ Limpieza y normalizaciÃ³n                                â”‚
â”‚  â€¢ DetecciÃ³n de idioma                                     â”‚
â”‚  â€¢ DeduplicaciÃ³n                                           â”‚
â”‚  â€¢ Filtros de calidad                                      â”‚
â”‚  â†’ Output: data/processed/dataset.parquet                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â”‚ dvc repro split
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               2. SPLIT ESTRATIFICADO                       â”‚
â”‚  â€¢ Train: 80%                                              â”‚
â”‚  â€¢ Dev: 10%                                                â”‚
â”‚  â€¢ Test: 10%                                               â”‚
â”‚  â†’ Outputs: train.parquet, dev.parquet, test.parquet      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                         â”‚
                    â–¼                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  3. CLASIFICADOR â”‚      â”‚  4. GENERADOR    â”‚
        â”‚   PLS/non-PLS    â”‚      â”‚     DE PLS       â”‚
        â”‚                  â”‚      â”‚                  â”‚
        â”‚  DistilBERT      â”‚      â”‚  BART/T5/LED     â”‚
        â”‚  F1_macro â‰¥ 0.85 â”‚      â”‚  ROUGE-L â‰¥ 0.35  â”‚
        â”‚                  â”‚      â”‚  BERTScore â‰¥ 0.85â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â”‚
                                           â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  5. SEMI-SUPERVISADO     â”‚
                            â”‚                          â”‚
                            â”‚  A. Teacher genera PLS   â”‚
                            â”‚     para non_pls         â”‚
                            â”‚  B. Filtros de calidad   â”‚
                            â”‚  C. Re-entrenar con LoRA â”‚
                            â”‚  D. Mejorar modelo       â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  6. EVALUACIÃ“N FINAL     â”‚
                            â”‚                          â”‚
                            â”‚  â€¢ ROUGE, BERTScore      â”‚
                            â”‚  â€¢ Flesch (legibilidad)  â”‚
                            â”‚  â€¢ Reportes por fuente   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â”‚ dvc push
                                           â–¼
                             [Modelos y Resultados en S3]
```

---

## ğŸ”„ Rol de DVC en el Proyecto

### Â¿Por QuÃ© DVC?

**Problemas que resuelve:**

1. **Datos grandes**: 65k+ archivos no caben en Git
2. **Versionado**: Necesitamos trackear diferentes versiones de datos
3. **ColaboraciÃ³n**: MÃºltiples personas trabajando con los mismos datos
4. **Reproducibilidad**: Ejecutar el mismo pipeline en diferentes mÃ¡quinas
5. **Experimentos**: Comparar resultados de diferentes configuraciones

### Â¿CÃ³mo Funciona DVC en Este Proyecto?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        GIT (CÃ³digo)                         â”‚
â”‚  â€¢ Scripts de Python (src/)                                 â”‚
â”‚  â€¢ Notebooks (notebooks/)                                   â”‚
â”‚  â€¢ ConfiguraciÃ³n (params.yaml, dvc.yaml)                    â”‚
â”‚  â€¢ Archivos DVC (*.dvc) â† Apuntan a datos en S3            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DVC (OrquestaciÃ³n)                      â”‚
â”‚  â€¢ Pipeline: preprocess â†’ split â†’ train â†’ evaluate         â”‚
â”‚  â€¢ Tracking de mÃ©tricas                                     â”‚
â”‚  â€¢ Cache local (.dvc/cache/)                                â”‚
â”‚  â€¢ GestiÃ³n de dependencias entre etapas                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              S3 (Almacenamiento de Datos)                   â”‚
â”‚  s3://pds-pls-data-prod/dvcstore/                           â”‚
â”‚  â€¢ Datos raw (65,941 archivos)                              â”‚
â”‚  â€¢ Datos procesados                                         â”‚
â”‚  â€¢ Modelos entrenados                                       â”‚
â”‚  â€¢ Outputs y evaluaciones                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Trabajo con DVC

**Para el lÃ­der del proyecto (tÃº):**
```bash
# 1. Modificar datos o cÃ³digo
# 2. Ejecutar pipeline
dvc repro

# 3. Subir resultados a S3
dvc push

# 4. Commit cambios al cÃ³digo
git add params.yaml dvc.yaml *.dvc
git commit -m "Experiment: improved preprocessing"
git push
```

**Para colaboradores:**
```bash
# 1. Clonar repo
git clone <url>

# 2. Configurar credenciales AWS
.\configure_aws.ps1

# 3. Descargar datos
dvc pull

# 4. Trabajar localmente
dvc repro

# 5. Subir sus cambios
dvc push
git push
```

---

## ğŸ“ Estructura de Archivos: Â¿QuÃ© Va DÃ³nde?

### En Git (cÃ³digo y configuraciÃ³n)
```
.
â”œâ”€â”€ src/                      # âœ… Git
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ loops/
â”œâ”€â”€ notebooks/                # âœ… Git
â”œâ”€â”€ docs/                     # âœ… Git
â”œâ”€â”€ params.yaml               # âœ… Git (parÃ¡metros)
â”œâ”€â”€ dvc.yaml                  # âœ… Git (pipeline)
â”œâ”€â”€ requirements.txt          # âœ… Git
â”œâ”€â”€ data/raw.dvc              # âœ… Git (puntero a datos)
â”œâ”€â”€ data/processed/*.dvc      # âœ… Git (punteros)
â””â”€â”€ models/*.dvc              # âœ… Git (punteros)
```

### En DVC/S3 (datos y modelos grandes)
```
s3://pds-pls-data-prod/dvcstore/
â”œâ”€â”€ files/md5/...             # âŒ Git, âœ… S3
â”‚   â”œâ”€â”€ [hash]/               # Datos raw
â”‚   â”œâ”€â”€ [hash]/               # Datos procesados
â”‚   â”œâ”€â”€ [hash]/               # Modelos entrenados
â”‚   â””â”€â”€ [hash]/               # Outputs
```

### Local (mientras trabajas)
```
.
â”œâ”€â”€ data/                     # âŒ Git, âœ… Local cache
â”‚   â”œâ”€â”€ raw/                  # Desde S3 via dvc pull
â”‚   â”œâ”€â”€ processed/            # Generado localmente
â”‚   â””â”€â”€ outputs/              # Generado localmente
â”œâ”€â”€ models/                   # âŒ Git, âœ… Local cache
â”‚   â”œâ”€â”€ pls_classifier/       # Generado localmente
â”‚   â””â”€â”€ generator_sft/        # Generado localmente
â””â”€â”€ .dvc/cache/               # âŒ Git, âœ… Local cache DVC
```

---

## ğŸ¯ Plan de EjecuciÃ³n (6 Semanas)

### âœ… Completado (Semana 0)
- [x] Configurar DVC con S3
- [x] Subir datos raw a S3 (65,941 archivos)
- [x] Crear documentaciÃ³n para colaboradores
- [x] Configurar `params.yaml` con todos los parÃ¡metros

### ğŸ“… Semana 1: Fundamentos
- [ ] EDA completo (distribuciÃ³n, estadÃ­sticas)
- [ ] Ejecutar preprocesamiento: `dvc repro preprocess`
- [ ] Validar `data/processed/dataset.parquet`
- [ ] Ejecutar split: `dvc repro split`
- [ ] Validar splits estratificados

**Comandos:**
```bash
jupyter notebook notebooks/01_EDA.ipynb
dvc repro preprocess
dvc repro split
dvc push
```

### ğŸ“… Semana 2: Clasificador
- [ ] Entrenar baseline (TF-IDF + LogReg)
- [ ] Entrenar DistilBERT
- [ ] Calibrar umbral
- [ ] Evaluar por fuente
- [ ] Target: F1_macro â‰¥ 0.85

**Comandos:**
```bash
dvc repro train_classifier
dvc metrics show
dvc push
```

### ğŸ“… Semana 3: Generador Supervisado
- [ ] Entrenar BART con pares reales
- [ ] Entrenar T5 para comparar
- [ ] Evaluar en dev y test
- [ ] Target: ROUGE-L â‰¥ 0.35

**Comandos:**
```bash
dvc repro train_generator
dvc metrics show
dvc push
```

### ğŸ“… Semana 4: Semi-Supervisado Ronda 1
- [ ] Implementar filtros
- [ ] Generar PLS sintÃ©ticos
- [ ] Re-entrenar con LoRA
- [ ] Evaluar mejora

### ğŸ“… Semana 5: Refinamiento
- [ ] Ronda 2 semi-supervisado
- [ ] Ablation studies
- [ ] Comparar BART vs T5

### ğŸ“… Semana 6: FinalizaciÃ³n
- [ ] EvaluaciÃ³n exhaustiva en test
- [ ] Dashboard Streamlit
- [ ] DocumentaciÃ³n final
- [ ] Reporte tÃ©cnico

---

## ğŸ’¡ Ventajas de Esta ConfiguraciÃ³n

### Para Ti (LÃ­der del Proyecto)

âœ… **Control total**: Todos los datos en S3 bajo tu control  
âœ… **Reproducible**: Cualquiera puede ejecutar `dvc repro` y obtener los mismos resultados  
âœ… **Trazabilidad**: Sabes exactamente quÃ© versiÃ³n de datos produjo quÃ© resultados  
âœ… **Backup automÃ¡tico**: S3 mantiene respaldo de todo  

### Para Colaboradores

âœ… **Setup rÃ¡pido**: Solo `git clone` + `dvc pull`  
âœ… **No necesitan datos en Git**: Descarga selectiva desde S3  
âœ… **Independencia**: Cada uno trabaja localmente sin conflictos  
âœ… **SincronizaciÃ³n fÃ¡cil**: `dvc pull` y `dvc push`  

### Para el Proyecto en General

âœ… **Escalable**: S3 puede manejar TB de datos  
âœ… **Versionado**: Volver a cualquier versiÃ³n anterior  
âœ… **Experimentos**: Comparar mÃºltiples configuraciones  
âœ… **Profesional**: EstÃ¡ndar de la industria  

---

## ğŸ“Š Ejemplo de Flujo Completo

### Escenario: Un colaborador quiere mejorar el preprocesamiento

```bash
# DÃA 1: Setup inicial
git clone <url>
cd "PROYECTO DE GRADO"
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# Configurar AWS
# (Solicitar credenciales al admin)
.\configure_aws.ps1

# Descargar datos
dvc pull                      # Descarga data/raw desde S3

# DÃA 2: ExploraciÃ³n
jupyter notebook notebooks/01_EDA.ipynb
# Identificar problema en limpieza de datos

# DÃA 3: ModificaciÃ³n
# Editar src/data/make_dataset.py
# Cambiar parÃ¡metros en params.yaml

# Ejecutar solo preprocesamiento
dvc repro preprocess          # Regenera data/processed/dataset.parquet

# Verificar resultado
python -c "import pandas as pd; print(pd.read_parquet('data/processed/dataset.parquet').info())"

# DÃA 4: Validar que funciona todo el pipeline
dvc repro                     # Ejecuta todo desde preprocess

# Si mejora las mÃ©tricas:
dvc push                      # Sube resultados a S3
git add src/data/make_dataset.py params.yaml data/processed/dataset.parquet.dvc
git commit -m "Improved data cleaning: removed HTML artifacts"
git push

# Otros colaboradores:
git pull                      # Obtienen el cÃ³digo nuevo
dvc pull                      # Obtienen los datos nuevos
```

---

## ğŸ“ Conceptos Clave para Entender

### 1. Â¿QuÃ© es un archivo .dvc?

Un archivo `.dvc` es un **puntero** a datos en S3. Ejemplo de `data/raw.dvc`:

```yaml
outs:
- md5: a3b5c7d9e1f2...
  size: 15728640000
  nfiles: 65941
  path: data/raw
```

Git guarda este archivo pequeÃ±o (KB), DVC usa el hash para descargar datos grandes (GB) desde S3.

### 2. Â¿QuÃ© es el pipeline de DVC?

`dvc.yaml` define **dependencias** entre etapas:

```yaml
stages:
  preprocess:
    cmd: python src/data/make_dataset.py
    deps:                         # Necesita estos archivos
      - src/data/make_dataset.py
      - data/raw
    params:                       # Usa estos parÃ¡metros
      - data
    outs:                         # Genera este output
      - data/processed/dataset.parquet
```

Si cambias `params.yaml` o `make_dataset.py`, DVC sabe que debe re-ejecutar `preprocess`.

### 3. Â¿QuÃ© es params.yaml?

Centraliza **todos los hiperparÃ¡metros**:

```yaml
data:
  min_chars: 30
classifier:
  lr: 2e-5
generator:
  base_model: "facebook/bart-base"
```

Cambiar un parÃ¡metro â†’ DVC re-ejecuta solo las etapas afectadas.

---

## âœ… Checklist Final

- [x] DVC configurado con S3
- [x] 65,941 archivos en S3
- [x] Credenciales AWS funcionando
- [x] Pipeline definido en dvc.yaml
- [x] ParÃ¡metros en params.yaml
- [x] DocumentaciÃ³n para colaboradores
- [x] Scripts de setup automatizados
- [ ] Primer experimento ejecutado
- [ ] Modelos entrenados
- [ ] Dashboard de visualizaciÃ³n

---

## ğŸ“š DocumentaciÃ³n Disponible

1. **`docs/GUIA_DESCARGA_DATOS_S3.md`** â­: GuÃ­a tÃ©cnica completa paso a paso para descargar datos
2. **`README_SETUP_RAPIDO.md`**: Setup rÃ¡pido en 5 pasos (~20 min)
3. **`docs/PLAN_PROYECTO.md`**: Plan detallado de 6 semanas con timeline
4. **`RESUMEN_PROYECTO_Y_DVC.md`**: Este archivo - explicaciÃ³n completa del proyecto
5. **`ARQUITECTURA.txt`**: DiseÃ±o tÃ©cnico detallado del sistema
6. **`README.md`**: Overview general del proyecto
7. **`params.yaml`**: ParÃ¡metros configurables del proyecto
8. **`dvc.yaml`**: DefiniciÃ³n del pipeline de datos

---

## ğŸš€ PrÃ³ximos Pasos Inmediatos

1. **Commit la configuraciÃ³n de DVC**
```bash
git add .dvc/ data/.gitignore data/raw.dvc .gitignore
git commit -m "Configure DVC with S3 and track raw data"
git push
```

2. **Ejecutar EDA**
```bash
jupyter notebook notebooks/01_EDA.ipynb
```

3. **Primera ejecuciÃ³n del pipeline**
```bash
dvc repro preprocess
dvc push
```

---

**Â¡El proyecto estÃ¡ completamente configurado y listo para desarrollar! ğŸ‰**

