# ğŸ“‹ Plan de Proyecto: Sistema PLS BiomÃ©dico con Semi-SupervisiÃ³n

## ğŸ¯ Objetivo General
Desarrollar un sistema de Machine Learning que genere Plain Language Summaries (PLS) de textos biomÃ©dicos complejos, usando tÃ©cnicas de aprendizaje semi-supervisado para aprovechar el gran volumen de datos no etiquetados.

---

## ğŸ“Š Contexto del Proyecto

### Datos Disponibles
- **Total**: ~182.7k documentos
- **Con PLS (etiquetados)**: ~27% (â‰ˆ49k documentos)
- **Sin PLS (no etiquetados)**: ~73% (â‰ˆ133k documentos)

### Fuentes de Datos
1. **ClinicalTrials.gov**: Ensayos clÃ­nicos
2. **Cochrane**: Revisiones sistemÃ¡ticas
3. **Pfizer**: Estudios clÃ­nicos (incluye PDFs)
4. **Trial Summaries**: ResÃºmenes de ensayos

### DesafÃ­o Principal
Gran desbalance entre datos etiquetados y no etiquetados â†’ **Necesidad de semi-supervisiÃ³n**

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATOS CRUDOS (S3)                       â”‚
â”‚  ClinicalTrials â”‚ Cochrane â”‚ Pfizer â”‚ Trial Summaries      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               1. PREPROCESAMIENTO                           â”‚
â”‚  â€¢ NormalizaciÃ³n y limpieza                                 â”‚
â”‚  â€¢ DetecciÃ³n de idioma (filtrar inglÃ©s)                     â”‚
â”‚  â€¢ DeduplicaciÃ³n por hash                                   â”‚
â”‚  â€¢ Filtros de calidad (longitud, formato)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               2. SPLIT ESTRATIFICADO                        â”‚
â”‚  Train: 80% â”‚ Dev: 10% â”‚ Test: 10%                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          3. CLASIFICADOR PLS/non-PLS                        â”‚
â”‚  Modelo: DistilBERT / BioBERT                               â”‚
â”‚  Objetivo: Detectar si texto ya es PLS                      â”‚
â”‚  MÃ©tricas: F1_macro â‰¥ 0.85                                  â”‚
â”‚  â€¢ Maneja desbalance con focal loss                         â”‚
â”‚  â€¢ Evita generar cuando ya es PLS (gate)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                   â”‚
         â–¼                                   â–¼
    [ES PLS]                           [NO ES PLS]
  Skip generaciÃ³n                    Pasar a generador
         â”‚                                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          4. GENERADOR PLS (Supervisado)                     â”‚
â”‚  Modelo: BART / T5 / LED                                    â”‚
â”‚  Datos: Solo pares reales (texto â†’ PLS)                     â”‚
â”‚  Training: Full Fine-Tuning o LoRA                          â”‚
â”‚  MÃ©tricas:                                                  â”‚
â”‚    â€¢ ROUGE-L â‰¥ 0.35-0.40                                    â”‚
â”‚    â€¢ BERTScore F1 â‰¥ 0.85                                    â”‚
â”‚    â€¢ Î”Flesch â‰¥ +15                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       5. BUCLE SEMI-SUPERVISADO (Opcional)                  â”‚
â”‚                                                             â”‚
â”‚  A. Teacher Model genera PLS para non-PLS                   â”‚
â”‚     â†“                                                       â”‚
â”‚  B. Filtros de Calidad (automÃ¡ticos)                        â”‚
â”‚     â€¢ Legibilidad: Flesch â‰¥ 60, Î” â‰¥ +15                    â”‚
â”‚     â€¢ Factualidad: BERTScore â‰¥ 0.85                         â”‚
â”‚     â€¢ Sin nÃºmeros nuevos                                    â”‚
â”‚     â€¢ Ratio de compresiÃ³n razonable                         â”‚
â”‚     â†“                                                       â”‚
â”‚  C. Pares SintÃ©ticos Aceptados                              â”‚
â”‚     â†“                                                       â”‚
â”‚  D. Re-entrenamiento con Mix 70:30 (real:sintÃ©tico)         â”‚
â”‚     â€¢ Usar LoRA para eficiencia                             â”‚
â”‚     â€¢ Early stopping en dev                                 â”‚
â”‚     â†“                                                       â”‚
â”‚  E. EvaluaciÃ³n â†’ Â¿Mejora? â†’ Siguiente ronda                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               6. EVALUACIÃ“N FINAL                           â”‚
â”‚  Con ground truth:                                          â”‚
â”‚    â€¢ ROUGE-L, BERTScore, Flesch, CompresiÃ³n                 â”‚
â”‚  Sin ground truth:                                          â”‚
â”‚    â€¢ Legibilidad, longitud, heurÃ­sticas                     â”‚
â”‚  Reportes:                                                  â”‚
â”‚    â€¢ Por fuente (Cochrane, Pfizer, etc.)                    â”‚
â”‚    â€¢ ComparaciÃ³n de modelos                                 â”‚
â”‚    â€¢ Ejemplos cualitativos                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         7. DASHBOARD DE VISUALIZACIÃ“N                       â”‚
â”‚  â€¢ Comparador de modelos                                    â”‚
â”‚  â€¢ MÃ©tricas interactivas                                    â”‚
â”‚  â€¢ Ejemplos originales vs generados                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“… Plan de EjecuciÃ³n (6 Semanas)

### **Semana 1: Fundamentos y Datos**
- [x] Configurar DVC con S3
- [ ] Ejecutar preprocesamiento completo
- [ ] AnÃ¡lisis exploratorio de datos (EDA)
- [ ] Validar distribuciÃ³n por fuente
- [ ] Confirmar splits estratificados

**Entregables**:
- `data/processed/dataset.parquet`
- `data/processed/{train,dev,test}.parquet`
- Notebook `notebooks/01_EDA.ipynb` actualizado

---

### **Semana 2: Clasificador PLS/non-PLS**
- [ ] Entrenar baseline (TF-IDF + Logistic Regression)
- [ ] Entrenar DistilBERT con focal loss
- [ ] Calibrar umbral de decisiÃ³n
- [ ] EvaluaciÃ³n por fuente (matriz de confusiÃ³n)
- [ ] Tunear hiperparÃ¡metros

**Entregables**:
- `models/pls_classifier/`
- `data/processed/classified.parquet`
- Reporte: `data/evaluation/classifier_report.json`

**MÃ©tricas Objetivo**:
- F1_macro â‰¥ 0.85
- Recall de PLS (minoritaria) â‰¥ 0.80

---

### **Semana 3: Generador Supervisado**
- [ ] Preparar pares reales (texto â†’ PLS)
- [ ] Entrenar BART-base con SFT
- [ ] Entrenar T5-base (comparaciÃ³n)
- [ ] Evaluar en dev y test
- [ ] Seleccionar mejor checkpoint

**Entregables**:
- `models/generator_sft/`
- `data/outputs/supervised/`
- Notebook de anÃ¡lisis cualitativo

**MÃ©tricas Objetivo**:
- ROUGE-L â‰¥ 0.35
- BERTScore F1 â‰¥ 0.85
- Î”Flesch â‰¥ +15

---

### **Semana 4: Semi-Supervisado - Ronda 1**
- [ ] Implementar filtros de aceptaciÃ³n
- [ ] Generar PLS sintÃ©ticos con teacher model
- [ ] Aplicar filtros (legibilidad, factualidad)
- [ ] Analizar tasa de aceptaciÃ³n
- [ ] Re-entrenar con LoRA (mix 70:30)
- [ ] Evaluar en dev

**Entregables**:
- `data/outputs/synthetic/round1/`
- `models/generator_lora_round1/`
- AnÃ¡lisis de calidad sintÃ©ticos vs reales

**Control de Calidad**:
- Tasa de aceptaciÃ³n â‰¥ 30%
- BERTScore sintÃ©ticos â‰¥ 0.83

---

### **Semana 5: Semi-Supervisado - Ronda 2 y Ablations**
- [ ] Ronda 2 de semi-supervisado (si ronda 1 fue exitosa)
- [ ] Experimentos de ablaciÃ³n:
  - Solo reales vs reales+sintÃ©ticos
  - Full-FT vs LoRA
  - BART vs T5
  - Con/sin clasificador gate

**Entregables**:
- `models/generator_lora_round2/`
- Tabla comparativa de experimentos
- Notebook de ablations

---

### **Semana 6: EvaluaciÃ³n Final y DocumentaciÃ³n**
- [ ] EvaluaciÃ³n exhaustiva en test set
- [ ] AnÃ¡lisis por fuente (Cochrane, Pfizer, etc.)
- [ ] Seleccionar 50 ejemplos cualitativos
- [ ] Dashboard Streamlit/Gradio
- [ ] DocumentaciÃ³n tÃ©cnica completa
- [ ] Reporte final

**Entregables**:
- `data/evaluation/final_report.json`
- Dashboard interactivo
- Reporte tÃ©cnico (PDF/Markdown)
- PresentaciÃ³n de resultados

---

## ğŸ”§ Stack TecnolÃ³gico

### Core ML
- **PyTorch**: Framework principal
- **Transformers (Hugging Face)**: Modelos pre-entrenados
- **PEFT**: LoRA para entrenamiento eficiente
- **Accelerate**: Distributed training

### Procesamiento de Datos
- **Pandas**: ManipulaciÃ³n de datos
- **PyArrow/Parquet**: Formato eficiente
- **scikit-learn**: MÃ©tricas y splits

### MÃ©tricas y EvaluaciÃ³n
- **rouge-score**: ROUGE metrics
- **bert-score**: Similarity semÃ¡ntica
- **textstat**: Legibilidad (Flesch)
- **NLTK**: AnÃ¡lisis de texto

### MLOps
- **DVC**: Versionado de datos y modelos
- **AWS S3**: Almacenamiento remoto
- **Git**: Versionado de cÃ³digo
- **Weights & Biases** (opcional): Tracking de experimentos

### VisualizaciÃ³n
- **Streamlit**: Dashboard interactivo
- **Matplotlib/Seaborn**: GrÃ¡ficos estÃ¡ticos
- **Plotly**: GrÃ¡ficos interactivos

---

## ğŸ“ MÃ©tricas de Ã‰xito

### Clasificador
| MÃ©trica | Objetivo | DescripciÃ³n |
|---------|----------|-------------|
| F1_macro | â‰¥ 0.85 | Balance entre PLS y non-PLS |
| Recall PLS | â‰¥ 0.80 | No perder textos que SÃ son PLS |
| Precision non-PLS | â‰¥ 0.90 | Evitar generar cuando no es necesario |

### Generador
| MÃ©trica | Objetivo | DescripciÃ³n |
|---------|----------|-------------|
| ROUGE-L | â‰¥ 0.35-0.40 | Overlap de secuencias mÃ¡s largas |
| BERTScore F1 | â‰¥ 0.85 | Similaridad semÃ¡ntica |
| Î”Flesch | â‰¥ +15 | Incremento en legibilidad |
| CompresiÃ³n | 0.3-0.8 | Ratio longitud PLS/original |

### Semi-Supervisado
| MÃ©trica | Objetivo | DescripciÃ³n |
|---------|----------|-------------|
| Tasa aceptaciÃ³n | â‰¥ 30% | % sintÃ©ticos que pasan filtros |
| BERTScore sintÃ©ticos | â‰¥ 0.83 | Calidad de pares sintÃ©ticos |
| Mejora en dev | +2-3% | Incremento sobre solo supervisado |

---

## ğŸš¨ Riesgos y Mitigaciones

### Riesgo 1: Desbalance extremo
**MitigaciÃ³n**:
- Focal loss con Î³=2.0
- Class weights balanceados
- Threshold tuning

### Riesgo 2: SintÃ©ticos de baja calidad
**MitigaciÃ³n**:
- Filtros multi-criterio estrictos
- ValidaciÃ³n con BERTScore
- Control de drift por ronda

### Riesgo 3: Modelos muy grandes (GPU limitada)
**MitigaciÃ³n**:
- Usar modelos -base en vez de -large
- LoRA para entrenamiento eficiente
- Gradient accumulation
- Mixed precision (fp16)

### Riesgo 4: PDFs de Pfizer no procesados
**MitigaciÃ³n**:
- Priorizar ClinicalTrials y Cochrane (ya en TXT/JSONL)
- PDFs como mejora futura (OCR/parsing)

---

## ğŸ“ Criterios de EvaluaciÃ³n AcadÃ©mica

### Aspectos TÃ©cnicos (60%)
- ImplementaciÃ³n correcta del pipeline completo âœ“
- Manejo adecuado del desbalance âœ“
- TÃ©cnicas de semi-supervisiÃ³n bien aplicadas âœ“
- EvaluaciÃ³n rigurosa con mÃºltiples mÃ©tricas âœ“

### ExperimentaciÃ³n (20%)
- Ablation studies comparando alternativas âœ“
- JustificaciÃ³n de decisiones de diseÃ±o âœ“
- AnÃ¡lisis de resultados por fuente âœ“

### DocumentaciÃ³n (15%)
- CÃ³digo limpio y documentado âœ“
- Reproducibilidad (DVC + seeds) âœ“
- Reporte tÃ©cnico completo âœ“

### InnovaciÃ³n (5%)
- Dashboard interactivo âœ“
- Filtros automÃ¡ticos de calidad âœ“
- AnÃ¡lisis cualitativo profundo âœ“

---

## ğŸ“š Referencias y Recursos

### Papers Relevantes
- **PLS Generation**: "Lay Summarization of Biomedical Research Articles" (EMNLP 2020)
- **Semi-Supervised NLP**: "Meta Pseudo Labels" (CVPR 2021)
- **Medical Text Summarization**: "Attention is All You Need" + BART/T5

### Datasets
- Cochrane Plain Language Summaries
- ClinicalTrials.gov
- PubMed abstracts

### Modelos Pre-entrenados
- `facebook/bart-base`: GeneraciÃ³n general
- `t5-base`: Text-to-text
- `allenai/led-base-16384`: Documentos largos
- `dmis-lab/biobert-base`: Dominio biomÃ©dico

---

## ğŸ”„ Workflow DVC Recomendado

```bash
# 1. Pull datos desde S3
dvc pull

# 2. Modificar parÃ¡metros
nano params.yaml

# 3. Ejecutar pipeline (solo etapas modificadas)
dvc repro

# 4. Revisar mÃ©tricas
dvc metrics show
dvc metrics diff

# 5. Push resultados a S3
dvc push

# 6. Commit cambios
git add params.yaml dvc.lock
git commit -m "Experiment: increased batch size"
git push
```

---

## ğŸ“ Contacto y Soporte

**DocumentaciÃ³n**:
- `docs/ARCHITECTURE.md`: Detalles tÃ©cnicos
- `docs/DVC_S3_SETUP.md`: ConfiguraciÃ³n DVC
- `docs/SETUP.md`: InstalaciÃ³n y ambiente

**Scripts Ãºtiles**:
- `setup_dvc_s3.ps1`: Configurar DVC en Windows
- `Makefile`: Comandos frecuentes

---

## âœ… Checklist de Inicio RÃ¡pido

- [ ] Instalar dependencias: `pip install -r requirements.txt`
- [ ] Configurar credenciales AWS (ver `docs/DVC_S3_SETUP.md`)
- [ ] Inicializar DVC remote: `.\setup_dvc_s3.ps1`
- [ ] Pull datos: `dvc pull`
- [ ] Ejecutar EDA: `jupyter notebook notebooks/01_EDA.ipynb`
- [ ] Revisar `params.yaml` y ajustar si necesario
- [ ] Ejecutar primera etapa: `dvc repro preprocess`

---

