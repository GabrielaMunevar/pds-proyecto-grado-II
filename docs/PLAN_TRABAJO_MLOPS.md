# Plan de Trabajo MLOps: PLS Biom√©dico

## Tabla de Evaluaci√≥n por Fases

| Fase | Score | Hallazgos | Archivos/Rutas Clave |
|------|-------|-----------|---------------------|
| **preprocess** | 3/3 |  Pipeline completo con 67,672 registros limpios<br/> Estad√≠sticas JSON generadas<br/> Filtros de calidad implementados (longitud, idioma, OCR) | `src/data/make_dataset.py`<br/>`data/processed/dataset_clean.csv`<br/>`data/processed/dataset_clean_stats.json` |
| **split** | 3/3 |  Divisi√≥n estratificada 80/20 reproducible<br/> Par√°metros en `params.yaml`<br/> Outputs: train.csv (54,138), test.csv (13,534) | `src/data/split_dataset.py`<br/>`data/processed/train.csv`<br/>`data/processed/test.csv` |
| **classifier** | 3/3 |  TF-IDF + Logistic Regression entrenado<br/> F1 Macro: 0.9952 (supera target 0.85)<br/> M√©tricas y modelos persistidos en `models/baseline_classifier/` | `src/models/train_classifier.py`<br/>`models/baseline_classifier/classifier.pkl`<br/>`models/baseline_classifier/metrics.json` |
| **generator** | 1/3 |  C√≥digo T5 verificado y testeado<br/> Pares sint√©ticos creados (21,527 pares)<br/> **CALIDAD INSUFICIENTE**: ROUGE-L 0.361 (target 0.38+)<br/> Modelo entrenado pero resultados pobres para proyecto | `src/models/train_t5_generator.py`<br/>`data/processed/synthetic_pairs/synthetic_pairs.jsonl`<br/>`models/t5_generator/` |
| **semi_supervised** | 0/3 |  No implementado<br/> Falta l√≥gica de iteraci√≥n<br/> Sin estrategia de selecci√≥n de datos no etiquetados | `src/models/semi_supervised.py` (no existe)<br/>`params.yaml` (sect: semi_supervised configurado) |
| **evaluation** | 2/3 |  Script ejecutado con √©xito<br/> M√©tricas ROUGE reportadas (0.361 L)<br/> Calidad del modelo identificada como problema cr√≠tico | `src/models/evaluate_generator.py`<br/>`models/t5_generator/evaluation_summary.json`<br/>`docs/EVALUACION_RESULTADOS.md` |
| **dashboard** | 0/3 |  No existe<br/> Sin UI/UX definida<br/> Sin Streamlit u otra herramienta | `src/dashboard/` (no existe)<br/>`streamlit_app.py` (no existe) |
| **dvc_s3** | 2/3 |  Scripts de configuraci√≥n existen<br/> `setup_dvc_s3.ps1` y `configure_aws.ps1` vac√≠os<br/> Pipeline DVC configurado (3 stages completados) | `dvc.yaml`<br/>`configure_aws.ps1` (vac√≠o)<br/>`setup_dvc_s3.ps1` (vac√≠o) |

## Brechas y Riesgos Cr√≠ticos

- **üö® CR√çTICO: Calidad Generador Insuficiente**: T5 entrenado produce ROUGE-L 0.361, **por debajo del target m√≠nimo 0.38** y muy lejos de producci√≥n (0.50+). Modelo actual no es viable para continuar con semi-supervisado.
- **Datos Sint√©ticos Limitados**: Solo 21K pares sint√©ticos (generados con reglas simples) vs 50K+ recomendados para transformers. Calidad de pares es pobre.
- **Dependencia GPU Externa**: El re-entrenamiento depende de Google Colab, creando bloqueo externo y dificultando iteraci√≥n r√°pida.
- **Semi-supervised Bloqueado**: No puede implementarse hasta mejorar base supervisada (T5 actual es mal teacher model).
- **Dashboard Inexistence**: Sin interfaz para demo o validaci√≥n cualitativa, dificultando iteraci√≥n con stakeholders.

## Plan de Trabajo

### üö® URGENTE: Mejorar Generador (BLOQUEO)

#### T1: Analizar Calidad de Pares Sint√©ticos
**Objetivo**: Identificar por qu√© los pares sint√©ticos generan modelo pobre

**Pasos**:
1. Revisar 100 pares aleatorios de `synthetic_pairs.jsonl` manualmente
2. Calcular m√©tricas promedio: compresi√≥n ratio, overlap l√©xico, Flesch delta
3. Identificar patrones problem√°ticos (demasiado literal, cambios m√≠nimos)
4. Generar reporte de calidad en `docs/ANALISIS_PARES_SINTETICOS.md`
5. Comparar con pares reales PLS si disponibles

**Criterio de aceptaci√≥n**: Reporte identifica 3+ problemas espec√≠ficos de calidad

---

#### T2: Generar M√°s Pares Sint√©ticos de Mejor Calidad
**Objetivo**: Expandir de 21K a 40K+ pares con mejor calidad

**Pasos**:
1. Ajustar par√°metros en `create_synthetic_pairs.py` (reemplazo l√©xico m√°s agresivo)
2. Implementar LLM-based augmentation (usar GPT-3.5 API o local)
3. Generar 30K adicionales pares de alta calidad
4. Validar muestra aleatoria (100 pares) manualmente
5. Actualizar `synthetic_pairs.jsonl` con nuevo dataset

**Criterio de aceptaci√≥n**: 40K+ pares con compresi√≥n ratio promedio 0.5-0.8 y overlap <70%

---

#### T3: Re-entrenar T5 con Mejores Datos y Par√°metros
**Objetivo**: Mejorar ROUGE-L de 0.361 a ‚â•0.42 (target mejorado)

**Pasos**:
1. Revisar hiperpar√°metros en `params.yaml` (LR, epochs, warmup)
2. Aumentar epochs a 5 (vs 3 actual)
3. Implementar learning rate scheduling m√°s suave
4. Entrenar en Google Colab con nuevo dataset
5. Evaluar y validar m√©tricas mejoradas

**Criterio de aceptaci√≥n**: ROUGE-L ‚â•0.42 (mejora de +0.06)

---

### Quick Wins (‚â§3 d√≠as) - Secundario

#### T4: Completar Scripts DVC-S3
**Objetivo**: Hacer reproducible el setup de entorno completo

**Pasos**:
1. Implementar `configure_aws.ps1` (credenciales AWS, permisos S3)
2. Implementar `setup_dvc_s3.ps1` (configurar DVC remote, inicializar cache)
3. Validar `dvc pull` descarga todos los raw files de S3
4. Documentar proceso en `docs/GUIA_DESCARGA_DATOS_S3.md`
5. Probar pipeline completo desde cero

**Criterio de aceptaci√≥n**: Ejecutar `dvc pull && dvc repro` completa sin errores

---

#### T3: Dashboard M√≠nimo Streamlit
**Objetivo**: Interfaz b√°sica para generar PLS desde texto

**Pasos**:
1. Crear `src/dashboard/app.py` con Streamlit
2. Implementar carga de modelo T5 (usar checkpoint existente)
3. Text area de entrada + bot√≥n de generaci√≥n
4. Mostrar texto original vs. PLS generado
5. A√±adir m√©tricas b√°sicas (longitud, Flesch Reading)

**Criterio de aceptaci√≥n**: Dashboard corre con `streamlit run src/dashboard/app.py` y genera PLS v√°lidos

---

### Bloques 1-2 Semanas

#### T7: Dashboard B√°sico para Demo y An√°lisis
**Objetivo**: Interfaz para evaluar calidad del generador mejorado

**Pasos**:
1. Crear `src/dashboard/app.py` con Streamlit
2. Implementar carga de modelo T5 (checkpoint mejorado)
3. Text area de entrada + bot√≥n de generaci√≥n
4. Mostrar texto original vs. PLS generado side-by-side
5. A√±adir m√©tricas (Flesch, suffixes, nuevas palabras)
6. Validar con stakeholders/usuarios reales

**Criterio de aceptaci√≥n**: Dashboard corre y permite evaluaci√≥n cualitativa de 20+ ejemplos

---

#### T8: Implementar Semi-supervisado (Iteraci√≥n 1) - **Solo si T1-T3 exitosos**
**Objetivo**: Reutilizar 46K textos no etiquetados con teacher model mejorado

**Pasos**:
1. **VALIDAR**: T5 mejorado tiene ROUGE-L ‚â•0.42 (si no, aplicar T3 nuevamente/LoRA)
2. Crear `src/models/semi_supervised.py`
3. Implementar generaci√≥n pseudo-labels (usar teacher: T5 mejorado)
4. Aplicar filtros de aceptaci√≥n (BERTScore ‚â•0.85, Flesch ‚â•60)
5. Seleccionar 1000 mejores muestras de datos no etiquetados
6. Fine-tune con LoRA (2 epochs) usando mix 70% real + 30% pseudo
7. Evaluar y comparar con baseline supervisado

**Criterio de aceptaci√≥n**: ROUGE-L mejora a ‚â•0.45 (mejora +0.03 desde baseline mejorado)

---

#### T9: Pipeline End-to-End Automatizado
**Objetivo**: Un √∫nico comando ejecuta todo el flujo

**Pasos**:
1. A√±adir stage `evaluate` en `dvc.yaml` (depende de T5 entrenado)
2. Crear `Makefile` targets: `make train-all`, `make evaluate-all`
3. Validar dependencias entre stages
4. Ejecutar `dvc repro` completo
5. Documentar en `README.md` con badge de status

**Criterio de aceptaci√≥n**: `make train-all` ejecuta preprocess ‚Üí split ‚Üí classifier ‚Üí pairs ‚Üí T5 ‚Üí evaluate

---

### Bloques 2-4 Semanas

#### T10: Iteraci√≥n Semi-supervisada Completa (2 rondas)
**Objetivo**: 2 rondas de re-entrenamiento con datos no etiquetados

**Pasos**:
1. Extender `semi_supervised.py` para manejar m√∫ltiples rondas
2. Seleccionar batches de 1000 textos no etiquetados por ronda (priorizar cortos primero)
3. Aplicar estrategia de selecci√≥n (`confidence`, `uncertainty`)
4. Validar early-stopping si `rouge_l_dev ‚â• 0.50`
5. Comparar m√©tricas finales vs. baseline supervisado
6. An√°lisis de ejemplos cualitativos (50 samples)

**Criterio de aceptaci√≥n**: ROUGE-L final ‚â•0.48 (mejora +0.06 desde T8, +0.12 desde inicio)

---

#### T11: Dashboard Avanzado con Comparaci√≥n
**Objetivo**: Herramienta completa de evaluaci√≥n y generaci√≥n

**Pasos**:
1. Expandir `src/dashboard/` con vistas: Compare Models, Batch Processing
2. Integrar comparaci√≥n T5 baseline vs. semi-supervisado
3. Visualizaciones: Distribuci√≥n de m√©tricas, ejemplos side-by-side
4. Exportar resultados a CSV/JSON
5. Deploy a Streamlit Cloud o local server

**Criterio de aceptaci√≥n**: Dashboard permite comparar 2+ modelos y exportar resultados

---

#### T12: Documentaci√≥n y Reproducibilidad
**Objetivo**: Proyecto completamente documentado y reproducible

**Pasos**:
1. Escribir `docs/GUIA_ENTRENAR_T5.md` (paso a paso Colab)
2. Actualizar `README.md` con badges, ejemplos de uso
3. Crear `docs/ARQUITECTURA_PROYECTO.md` con diagramas actualizados
4. Validar que nuevo colaborador puede reproducir desde `git clone`
5. A√±adir unit tests cr√≠ticos (`tests/`)

**Criterio de aceptaci√≥n**: Documentaci√≥n permite reproducir proyecto en <2 horas

---

## Issues JSON (Tareas de GitHub/GitLab)

```json
{
  "issues": [
    {
      "title": "üö® CR√çTICO: Analizar calidad de pares sint√©ticos (21K)",
      "labels": ["critical", "data", "blocking"],
      "steps": [
        "Revisar 100 pares aleatorios manualmente",
        "Calcular m√©tricas: compresi√≥n, overlap, Flesch delta",
        "Identificar patrones problem√°ticos",
        "Generar reporte en docs/ANALISIS_PARES_SINTETICOS.md"
      ]
    },
    {
      "title": "üö® CR√çTICO: Generar m√°s pares sint√©ticos (21K ‚Üí 40K+ con mejor calidad)",
      "labels": ["critical", "data", "blocking"],
      "steps": [
        "Ajustar par√°metros create_synthetic_pairs.py",
        "Implementar LLM-based augmentation",
        "Generar 30K adicionales",
        "Validar muestra aleatoria manualmente"
      ]
    },
    {
      "title": "üö® CR√çTICO: Re-entrenar T5 con datos mejorados (target: ROUGE-L ‚â•0.42)",
      "labels": ["critical", "training", "generator", "blocking"],
      "steps": [
        "Ajustar hiperpar√°metros (LR, epochs=5)",
        "Entrenar en Google Colab con nuevo dataset",
        "Evaluar m√©tricas",
        "Validar mejora de +0.06 ROUGE-L"
      ]
    },
    {
      "title": "Completar scripts de configuraci√≥n DVC-S3",
      "labels": ["infrastructure", "dvc"],
      "steps": [
        "Implementar configure_aws.ps1",
        "Implementar setup_dvc_s3.ps1",
        "Validar dvc pull funciona",
        "Documentar en GUIA_DESCARGA_DATOS_S3.md"
      ]
    },
    {
      "title": "Crear dashboard Streamlit b√°sico para evaluar generador",
      "labels": ["dashboard", "ui"],
      "steps": [
        "Crear src/dashboard/app.py",
        "Implementar carga de modelo T5 mejorado",
        "Text area + bot√≥n generaci√≥n",
        "Mostrar m√©tricas (Flesch, overlap)"
      ]
    },
    {
      "title": "Implementar bucle semi-supervisado (requiere T5 ROUGE-L ‚â•0.42)",
      "labels": ["semi-supervised", "generator", "priority-high"],
      "steps": [
        "Crear src/models/semi_supervised.py",
        "Generar pseudo-labels con teacher model",
        "Aplicar filtros aceptaci√≥n",
        "Fine-tune con LoRA en mix 70/30"
      ]
    },
    {
      "title": "Automatizar pipeline end-to-end con DVC y Makefile",
      "labels": ["pipeline", "automation", "dvc"],
      "steps": [
        "A√±adir stage evaluate en dvc.yaml",
        "Crear Makefile targets",
        "Validar dependencias",
        "Documentar en README"
      ]
    },
    {
      "title": "Iteraci√≥n completa semi-supervisada (2 rondas)",
      "labels": ["semi-supervised", "generator"],
      "steps": [
        "Extender para m√∫ltiples rondas",
        "Implementar selecci√≥n batches",
        "Aplicar early-stopping",
        "Comparar m√©tricas finales"
      ]
    },
    {
      "title": "Completar scripts de configuraci√≥n DVC-S3 (configure_aws.ps1)",
      "labels": ["infrastructure", "dvc", "quick-win"],
      "steps": [
        "Implementar configuraci√≥n credenciales AWS",
        "Configurar permisos S3 bucket",
        "Validar dvc pull funciona",
        "Documentar proceso en GUIA_DESCARGA_DATOS_S3.md"
      ]
    },
    {
      "title": "Crear dashboard Streamlit b√°sico para generaci√≥n PLS",
      "labels": ["dashboard", "quick-win", "ui"],
      "steps": [
        "Crear src/dashboard/app.py",
        "Implementar carga de modelo T5",
        "Text area + bot√≥n generaci√≥n",
        "Mostrar m√©tricas b√°sicas (Flesch)"
      ]
    },
    {
      "title": "Fine-tune T5-small en Google Colab con 21K pares sint√©ticos",
      "labels": ["training", "generator", "priority-high"],
      "steps": [
        "Adaptar train_t5_generator.py para Colab",
        "Upload datos a Colab",
        "Configurar GPU runtime",
        "Entrenar 3 epochs con checkpoints",
        "Descargar modelo final"
      ]
    },
    {
      "title": "Implementar bucle semi-supervisado (primera iteraci√≥n)",
      "labels": ["semi-supervised", "generator", "priority-high"],
      "steps": [
        "Crear src/models/semi_supervised.py",
        "Generar pseudo-labels con teacher model",
        "Aplicar filtros aceptaci√≥n",
        ·ª©ng "Fine-tune con LoRA en mix 70/30",
        "Evaluar y comparar"
      ]
    },
    {
      "title": "Automatizar pipeline end-to-end con DVC y Makefile",
      "labels": ["pipeline", "automation", "dvc"],
      "steps": [
        "A√±adir stage evaluate en dvc.yaml",
        "Crear Makefile targets",
        "Validar dependencias",
        "Documentar en README"
      ]
    },
    {
      "title": "Iteraci√≥n completa semi-supervisada (2 rondas)",
      "labels": ["semi-supervised", "generator", "priority-medium"],
      "steps": [
        "Extender para m√∫ltiples rondas",
        "Implementar selecci√≥n batches",
        "Aplicar early-stopping",
        "Comparar m√©tricas finales"
      ]
    },
    {
      "title": "Expander dashboard con comparaci√≥n modelos y visualizaciones",
      "labels": ["dashboard", "ui", "priority-medium"],
      "steps": [
        "A√±adir vista Compare Models",
        "Implementar visualizaciones m√©tricas",
        "Exportar resultados CSV/JSON",
        "Deploy a Streamlit Cloud"
      ]
    },
    {
      "title": "Documentar proyecto completo y validar reproducibilidad",
      "labels": ["documentation", "reproducibility", "priority-low"],
      "steps": [
        "Escribir GUIA_ENTRENAR_T5.md",
        "Actualizar README con badges",
        "Crear tests unitarios",
        "Validar colaborador nuevo puede reproducir"
      ]
    },
    {
      "title": "Optimizar generaci√≥n de pares sint√©ticos (21K ‚Üí target mayor)",
      "labels": ["data", "synthetic", "priority-low"],
      "steps": [
        "Analizar calidad pares existentes",
        "Ajustar par√°metros create_synthetic_pairs.py",
        "Generar 30K+ pares",
        "Validar distribuci√≥n balanceada"
      ]
    }
  ]
}
```

---

## Resumen Ejecutivo

**Estado Actual**: Pipeline DVC con 4/8 fases completadas (50%). Preprocess, split y classifier funcionando excelentemente (F1: 0.9952). Generador T5 entrenado pero con **calidad insuficiente**: ROUGE-L 0.361 (por debajo del target 0.38+). Evaluaci√≥n ejecutada, semi-supervisado bloqueado.

**üö® PROBLEMA CR√çTICO**: El modelo T5 actual (ROUGE-L 0.361) no es viable para:
- Continuar con semi-supervisado (teacher model pobre)
- Presentar resultados de calidad
- Producci√≥n

**Prioridades Inmediatas (BLOQUEO)**: 
1. Analizar calidad pares sint√©ticos (21K) y generar reporte
2. Generar m√°s pares sint√©ticos (40K+ con mejor calidad)
3. Re-entrenar T5 con datos mejorados (target: ROUGE-L ‚â•0.42)

**Riesgo Principal**: Calidad de datos sint√©ticos pobres genera modelo insuficiente. Dependencia de GPU externa (Colab).

**Criterio de √âxito**: ROUGE-L ‚â•0.42 (vs 0.361 actual), luego iterar con semi-supervisado para alcanzar ‚â•0.48.

